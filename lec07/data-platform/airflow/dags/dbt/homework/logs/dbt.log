[0m12:54:38.373681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad945eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaca43850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaca437f0>]}


============================== 12:54:38.378905 | ee344545-a8b0-40bd-a2d8-eba9dc2e6ce1 ==============================
[0m12:54:38.378905 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:54:38.379445 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:54:38.459003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee344545-a8b0-40bd-a2d8-eba9dc2e6ce1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaca71400>]}
[0m12:54:38.467224 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-dxsa9sx4'
[0m12:54:38.467925 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:54:38.800487 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:54:38.801229 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:54:38.988139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81dd8ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80ec3940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80ec38e0>]}


============================== 12:54:38.993266 | f89b730e-b38f-4130-bd8e-1e7f06a0f73a ==============================
[0m12:54:38.993266 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:54:38.993991 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'send_anonymous_usage_stats': 'True'}
[0m12:54:39.073680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f89b730e-b38f-4130-bd8e-1e7f06a0f73a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80fa6be0>]}
[0m12:54:39.081925 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-9om3qyh3'
[0m12:54:39.082560 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:54:39.218527 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:54:39.222832 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:54:39.276361 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:54:39.277169 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m12:54:39.394329 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:54:39.409383 [info ] [MainThread]: Updating lock file in file path: /opt/airflow/dags/dbt/homework/package-lock.yml
[0m12:54:39.413084 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-_0i0vyv7'
[0m12:54:39.417447 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:54:39.452117 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m12:54:39.456226 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:54:39.656871 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:54:39.674825 [info ] [MainThread]: Updating lock file in file path: /opt/airflow/dags/dbt/homework/package-lock.yml
[0m12:54:39.680199 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-j7o2t4j4'
[0m12:54:39.684631 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m12:54:40.338743 [info ] [MainThread]: Installed from version 0.2.4
[0m12:54:40.339202 [info ] [MainThread]: Up to date!
[0m12:54:40.339531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ee344545-a8b0-40bd-a2d8-eba9dc2e6ce1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac9a7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac8d6e50>]}
[0m12:54:40.339877 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:54:40.535501 [info ] [MainThread]: Installed from version 0.2.4
[0m12:54:40.536309 [info ] [MainThread]: Up to date!
[0m12:54:40.536814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f89b730e-b38f-4130-bd8e-1e7f06a0f73a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b28940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80d56d00>]}
[0m12:54:40.537381 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:54:40.929806 [info ] [MainThread]: Installed from version 1.3.0
[0m12:54:40.930326 [info ] [MainThread]: Up to date!
[0m12:54:40.930746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ee344545-a8b0-40bd-a2d8-eba9dc2e6ce1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac9a7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac8d6070>]}
[0m12:54:40.931960 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.5952938, "process_in_blocks": "0", "process_kernel_time": 0.153433, "process_mem_max_rss": "89044", "process_out_blocks": "13550", "process_user_time": 1.534335}
[0m12:54:40.932674 [debug] [MainThread]: Command `dbt deps` succeeded at 12:54:40.932560 after 2.60 seconds
[0m12:54:40.933111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad945eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaca71400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac969af0>]}
[0m12:54:40.933612 [debug] [MainThread]: Flushing usage events
[0m12:54:41.168215 [info ] [MainThread]: Installed from version 1.3.0
[0m12:54:41.168893 [info ] [MainThread]: Up to date!
[0m12:54:41.169358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'f89b730e-b38f-4130-bd8e-1e7f06a0f73a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b28940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80d56df0>]}
[0m12:54:41.170547 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.2171593, "process_in_blocks": "0", "process_kernel_time": 0.148388, "process_mem_max_rss": "88644", "process_out_blocks": "13550", "process_user_time": 1.544044}
[0m12:54:41.171230 [debug] [MainThread]: Command `dbt deps` succeeded at 12:54:41.171132 after 2.22 seconds
[0m12:54:41.171705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81dd8ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81c4eb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80fa6cd0>]}
[0m12:54:41.172150 [debug] [MainThread]: Flushing usage events
[0m12:54:41.800802 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:54:41.801179 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:02.141798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e4dc4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e272a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d6988b0>]}


============================== 10:52:02.147234 | 64bb74d2-c8d7-48b2-9c40-e0c5b0b4ad8a ==============================
[0m10:52:02.147234 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:52:02.147952 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:52:02.234306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64bb74d2-c8d7-48b2-9c40-e0c5b0b4ad8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d6cf6d0>]}
[0m10:52:02.333958 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-5d140r2_'
[0m10:52:02.334552 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m10:52:02.581675 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m10:52:02.582415 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m10:52:02.718324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b0ca550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a1d0f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a1d0f10>]}


============================== 10:52:02.723118 | ae7e745c-e7df-418d-b372-6d350b0c5f61 ==============================
[0m10:52:02.723118 [info ] [MainThread]: Running with dbt=1.9.4
[0m10:52:02.723884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:02.788076 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m10:52:02.789131 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m10:52:02.800617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ae7e745c-e7df-418d-b372-6d350b0c5f61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c6e44c0>]}
[0m10:52:02.811553 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-gzearv1e'
[0m10:52:02.812083 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m10:52:02.856354 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m10:52:02.859478 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m10:52:02.882541 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m10:52:02.883203 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m10:52:02.949713 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m10:52:02.950927 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m10:52:03.017674 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m10:52:03.021851 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m10:52:03.572370 [info ] [MainThread]: Installed from version 0.2.4
[0m10:52:03.573064 [info ] [MainThread]: Up to date!
[0m10:52:03.573831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '64bb74d2-c8d7-48b2-9c40-e0c5b0b4ad8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2382b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e8caf40>]}
[0m10:52:03.574904 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m10:52:03.682032 [info ] [MainThread]: Installed from version 0.2.4
[0m10:52:03.682703 [info ] [MainThread]: Up to date!
[0m10:52:03.683285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ae7e745c-e7df-418d-b372-6d350b0c5f61', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8af62550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a1420d0>]}
[0m10:52:03.683731 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m10:52:04.272540 [info ] [MainThread]: Installed from version 1.3.0
[0m10:52:04.273341 [info ] [MainThread]: Up to date!
[0m10:52:04.274013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ae7e745c-e7df-418d-b372-6d350b0c5f61', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8af62550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a01c9a0>]}
[0m10:52:04.275413 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.591212, "process_in_blocks": "0", "process_kernel_time": 0.224587, "process_mem_max_rss": "89184", "process_out_blocks": "7800", "process_user_time": 1.599018}
[0m10:52:04.276041 [debug] [MainThread]: Command `dbt deps` succeeded at 10:52:04.275954 after 1.59 seconds
[0m10:52:04.276473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b0ca550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c6e44c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8dd0ba00>]}
[0m10:52:04.276876 [debug] [MainThread]: Flushing usage events
[0m10:52:04.420798 [info ] [MainThread]: Installed from version 1.3.0
[0m10:52:04.421468 [info ] [MainThread]: Up to date!
[0m10:52:04.421998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '64bb74d2-c8d7-48b2-9c40-e0c5b0b4ad8a', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d5d9940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d5d9a60>]}
[0m10:52:04.423205 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.3201475, "process_in_blocks": "0", "process_kernel_time": 0.289459, "process_mem_max_rss": "89052", "process_out_blocks": "7800", "process_user_time": 1.649196}
[0m10:52:04.424014 [debug] [MainThread]: Command `dbt deps` succeeded at 10:52:04.423876 after 2.32 seconds
[0m10:52:04.424579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e4dc4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e8caf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d557040>]}
[0m10:52:04.425188 [debug] [MainThread]: Flushing usage events
[0m10:52:04.913027 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:04.982656 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:29:37.538469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6d18580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5e1ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5e1ff70>]}


============================== 11:29:37.543879 | b672ee0a-0ac2-4788-9ef2-55a958935f28 ==============================
[0m11:29:37.543879 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:29:37.544524 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:29:37.626503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b672ee0a-0ac2-4788-9ef2-55a958935f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5de9c70>]}
[0m11:29:37.682143 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-rhq0qp7j'
[0m11:29:37.682870 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:29:37.764607 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:29:37.765283 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m11:29:38.093405 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m11:29:38.094537 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:29:38.162448 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:29:38.165550 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m11:29:38.191424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ff2b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f031fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f031f70>]}


============================== 11:29:38.196236 | 422d2beb-a372-4173-9bde-a6a001344624 ==============================
[0m11:29:38.196236 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:29:38.197043 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps --profiles-dir /opt/airflow/dags/dbt --project-dir /opt/airflow/dags/dbt/homework', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:29:38.273510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '422d2beb-a372-4173-9bde-a6a001344624', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9effbc70>]}
[0m11:29:38.284570 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-0i915i3k'
[0m11:29:38.285089 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:29:38.358947 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:29:38.359655 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json
[0m11:29:38.423327 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/Matts52/dbt_ml_inline_preprocessing.json 200
[0m11:29:38.424561 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:29:38.495627 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:29:38.500731 [info ] [MainThread]: Installing Matts52/dbt_ml_inline_preprocessing
[0m11:29:38.861654 [info ] [MainThread]: Installed from version 0.2.4
[0m11:29:38.862342 [info ] [MainThread]: Up to date!
[0m11:29:38.863027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b672ee0a-0ac2-4788-9ef2-55a958935f28', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6bd7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6b905e0>]}
[0m11:29:38.863920 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m11:29:39.117327 [info ] [MainThread]: Installed from version 0.2.4
[0m11:29:39.117950 [info ] [MainThread]: Up to date!
[0m11:29:39.118402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '422d2beb-a372-4173-9bde-a6a001344624', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fde7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9efa3070>]}
[0m11:29:39.118844 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m11:29:39.354346 [info ] [MainThread]: Installed from version 1.3.0
[0m11:29:39.355138 [info ] [MainThread]: Up to date!
[0m11:29:39.355787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b672ee0a-0ac2-4788-9ef2-55a958935f28', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6bd7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5da4c10>]}
[0m11:29:39.357101 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.8555149, "process_in_blocks": "0", "process_kernel_time": 0.222322, "process_mem_max_rss": "89220", "process_out_blocks": "7800", "process_user_time": 1.565438}
[0m11:29:39.358214 [debug] [MainThread]: Command `dbt deps` succeeded at 11:29:39.358123 after 1.86 seconds
[0m11:29:39.358836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6d18580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5d86790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7c1ec10>]}
[0m11:29:39.359580 [debug] [MainThread]: Flushing usage events
[0m11:29:39.658529 [info ] [MainThread]: Installed from version 1.3.0
[0m11:29:39.659091 [info ] [MainThread]: Up to date!
[0m11:29:39.659664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '422d2beb-a372-4173-9bde-a6a001344624', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fde7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9efb2c10>]}
[0m11:29:39.660907 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.5055269, "process_in_blocks": "0", "process_kernel_time": 0.202698, "process_mem_max_rss": "89100", "process_out_blocks": "7800", "process_user_time": 1.571945}
[0m11:29:39.661585 [debug] [MainThread]: Command `dbt deps` succeeded at 11:29:39.661457 after 1.51 seconds
[0m11:29:39.662240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ff2b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9efb5040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0e30c10>]}
[0m11:29:39.662868 [debug] [MainThread]: Flushing usage events
[0m11:29:39.903968 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:29:40.202998 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:37:41.016046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff822769a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81392550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff813924f0>]}


============================== 15:37:41.023188 | 09b5e298-63e7-4321-a0d6-969f01eccfc1 ==============================
[0m15:37:41.023188 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:37:41.024319 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m15:37:41.170006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80979940>]}
[0m15:37:41.207564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80979460>]}
[0m15:37:41.208605 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:37:41.274285 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m15:37:41.276170 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:37:41.276749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8083e760>]}
[0m15:37:42.288436 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m15:37:42.296147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f961f10>]}
[0m15:37:42.362239 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:37:42.367155 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:37:42.379080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f968220>]}
[0m15:37:42.379634 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m15:37:42.380090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fa90bb0>]}
[0m15:37:42.381192 [info ] [MainThread]: 
[0m15:37:42.381607 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:37:42.382000 [info ] [MainThread]: 
[0m15:37:42.382590 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:37:42.383351 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m15:37:42.404329 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m15:37:42.404860 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m15:37:42.405317 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:42.415943 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m15:37:42.416930 [debug] [ThreadPool]: On list_analytics: Close
[0m15:37:42.419987 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m15:37:42.424404 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:37:42.424856 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m15:37:42.425251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:37:42.435714 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m15:37:42.436217 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:37:42.436615 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m15:37:42.440592 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m15:37:42.441612 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m15:37:42.442224 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m15:37:42.445929 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.446546 [debug] [MainThread]: On master: BEGIN
[0m15:37:42.447008 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:37:42.455424 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m15:37:42.455878 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.456322 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:37:42.459976 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m15:37:42.460928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80972820>]}
[0m15:37:42.461452 [debug] [MainThread]: On master: ROLLBACK
[0m15:37:42.462006 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.462398 [debug] [MainThread]: On master: BEGIN
[0m15:37:42.462947 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m15:37:42.463352 [debug] [MainThread]: On master: COMMIT
[0m15:37:42.463723 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.464094 [debug] [MainThread]: On master: COMMIT
[0m15:37:42.464554 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:37:42.464917 [debug] [MainThread]: On master: Close
[0m15:37:42.467901 [debug] [Thread-1  ]: Began running node model.homework.iris_processed
[0m15:37:42.468622 [info ] [Thread-1  ]: 1 of 1 START sql table model analytics.iris_processed .......................... [RUN]
[0m15:37:42.469253 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.iris_processed)
[0m15:37:42.469697 [debug] [Thread-1  ]: Began compiling node model.homework.iris_processed
[0m15:37:42.482332 [debug] [Thread-1  ]: Using postgres connection "model.homework.iris_processed"
[0m15:37:42.482864 [debug] [Thread-1  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m15:37:42.483278 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:37:42.490990 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "analytics.stg_iris" does not exist
LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                             ^

[0m15:37:42.492651 [debug] [Thread-1  ]: On model.homework.iris_processed: Close
[0m15:37:42.494478 [debug] [Thread-1  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:37:42.495738 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09b5e298-63e7-4321-a0d6-969f01eccfc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82148850>]}
[0m15:37:42.496339 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.03s]
[0m15:37:42.496840 [debug] [Thread-1  ]: Finished running node model.homework.iris_processed
[0m15:37:42.497305 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^.
[0m15:37:42.498552 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.498886 [debug] [MainThread]: On master: BEGIN
[0m15:37:42.499172 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:37:42.506361 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m15:37:42.506780 [debug] [MainThread]: On master: COMMIT
[0m15:37:42.507127 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:42.507513 [debug] [MainThread]: On master: COMMIT
[0m15:37:42.507960 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:37:42.508305 [debug] [MainThread]: On master: Close
[0m15:37:42.508727 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:37:42.509021 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m15:37:42.509358 [info ] [MainThread]: 
[0m15:37:42.509725 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.13 seconds (0.13s).
[0m15:37:42.510302 [debug] [MainThread]: Command end result
[0m15:37:42.541887 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:37:42.543569 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:37:42.547592 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m15:37:42.547968 [info ] [MainThread]: 
[0m15:37:42.548401 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:37:42.548764 [info ] [MainThread]: 
[0m15:37:42.549156 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:37:42.549503 [info ] [MainThread]: 
[0m15:37:42.549876 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:37:42.550660 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.573686, "process_in_blocks": "0", "process_kernel_time": 0.266527, "process_mem_max_rss": "111764", "process_out_blocks": "0", "process_user_time": 2.457526}
[0m15:37:42.551165 [debug] [MainThread]: Command `dbt run` failed at 15:37:42.551108 after 1.57 seconds
[0m15:37:42.551567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff822769a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff827f4b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80979460>]}
[0m15:37:42.551972 [debug] [MainThread]: Flushing usage events
[0m15:37:43.116356 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:44.461682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c89e9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7b9ba550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7b9ba4f0>]}


============================== 15:40:44.471038 | f7cc2bfc-72ff-4dc5-9d81-b7971fd76156 ==============================
[0m15:40:44.471038 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:40:44.473608 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m15:40:44.675135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7afa1940>]}
[0m15:40:44.712801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7afa1460>]}
[0m15:40:44.713852 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:40:44.786053 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m15:40:44.908480 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:40:44.909394 [debug] [MainThread]: Partial parsing: updated file: homework://models/mart/iris_processed.sql
[0m15:40:45.175759 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m15:40:45.184233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a7b49d0>]}
[0m15:40:45.258165 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:40:45.263024 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:40:45.274822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a7d8250>]}
[0m15:40:45.275365 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m15:40:45.275782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7aa297c0>]}
[0m15:40:45.277026 [info ] [MainThread]: 
[0m15:40:45.277444 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:40:45.277841 [info ] [MainThread]: 
[0m15:40:45.278353 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:40:45.279154 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m15:40:45.303267 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m15:40:45.303910 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m15:40:45.304339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:40:45.316276 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m15:40:45.317614 [debug] [ThreadPool]: On list_analytics: Close
[0m15:40:45.321588 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m15:40:45.326330 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:40:45.326863 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m15:40:45.327231 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:40:45.335930 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m15:40:45.336430 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:40:45.336859 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m15:40:45.340782 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:40:45.341822 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m15:40:45.342358 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m15:40:45.345938 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.346474 [debug] [MainThread]: On master: BEGIN
[0m15:40:45.346877 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:40:45.354373 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m15:40:45.354898 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.355421 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:40:45.359802 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m15:40:45.360920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eb51f70>]}
[0m15:40:45.361504 [debug] [MainThread]: On master: ROLLBACK
[0m15:40:45.362295 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.362848 [debug] [MainThread]: On master: BEGIN
[0m15:40:45.363519 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m15:40:45.363910 [debug] [MainThread]: On master: COMMIT
[0m15:40:45.364280 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.364640 [debug] [MainThread]: On master: COMMIT
[0m15:40:45.365122 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:40:45.365581 [debug] [MainThread]: On master: Close
[0m15:40:45.368482 [debug] [Thread-1  ]: Began running node model.homework.iris_processed
[0m15:40:45.369118 [info ] [Thread-1  ]: 1 of 1 START sql table model analytics.iris_processed .......................... [RUN]
[0m15:40:45.369710 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.iris_processed)
[0m15:40:45.370151 [debug] [Thread-1  ]: Began compiling node model.homework.iris_processed
[0m15:40:45.383339 [debug] [Thread-1  ]: Using postgres connection "model.homework.iris_processed"
[0m15:40:45.384061 [debug] [Thread-1  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m15:40:45.384584 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:40:45.393615 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "analytics.stg_iris" does not exist
LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                             ^

[0m15:40:45.395682 [debug] [Thread-1  ]: On model.homework.iris_processed: Close
[0m15:40:45.397798 [debug] [Thread-1  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:40:45.399432 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7cc2bfc-72ff-4dc5-9d81-b7971fd76156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c771850>]}
[0m15:40:45.400350 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.03s]
[0m15:40:45.401290 [debug] [Thread-1  ]: Finished running node model.homework.iris_processed
[0m15:40:45.401980 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^.
[0m15:40:45.403456 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.404010 [debug] [MainThread]: On master: BEGIN
[0m15:40:45.404495 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:40:45.412561 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m15:40:45.413112 [debug] [MainThread]: On master: COMMIT
[0m15:40:45.413522 [debug] [MainThread]: Using postgres connection "master"
[0m15:40:45.414048 [debug] [MainThread]: On master: COMMIT
[0m15:40:45.414644 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:40:45.415066 [debug] [MainThread]: On master: Close
[0m15:40:45.415618 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:40:45.416086 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m15:40:45.416581 [info ] [MainThread]: 
[0m15:40:45.417486 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m15:40:45.418265 [debug] [MainThread]: Command end result
[0m15:40:45.467441 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:40:45.470202 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:40:45.475224 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m15:40:45.476114 [info ] [MainThread]: 
[0m15:40:45.476744 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:40:45.477237 [info ] [MainThread]: 
[0m15:40:45.477691 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:40:45.478077 [info ] [MainThread]: 
[0m15:40:45.478570 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:40:45.480106 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0856076, "process_in_blocks": "0", "process_kernel_time": 0.240199, "process_mem_max_rss": "112420", "process_out_blocks": "0", "process_user_time": 1.894232}
[0m15:40:45.480772 [debug] [MainThread]: Command `dbt run` failed at 15:40:45.480715 after 1.09 seconds
[0m15:40:45.481334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c89e9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ae56c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a7d8250>]}
[0m15:40:45.481915 [debug] [MainThread]: Flushing usage events
[0m15:40:46.035117 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:43:07.985278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c8429a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b95e550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b95e4f0>]}


============================== 15:43:07.990781 | b4a3deba-196f-4434-9168-7b7a7284d12f ==============================
[0m15:43:07.990781 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:43:07.991468 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart --vars {"is_test": false, "data_date": "2025-05-10"}', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:43:08.122985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4a3deba-196f-4434-9168-7b7a7284d12f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8af45940>]}
[0m15:43:08.156021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4a3deba-196f-4434-9168-7b7a7284d12f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8af45460>]}
[0m15:43:08.157050 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:43:08.221163 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m15:43:08.334806 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:43:08.335597 [debug] [MainThread]: Partial parsing: updated file: homework://models/mart/iris_processed.sql
[0m15:43:08.654473 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.homework.iris_processed' (models/mart/iris_processed.sql) depends on a node named 'iris_dataset' which was not found
[0m15:43:08.655877 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.70960414, "process_in_blocks": "0", "process_kernel_time": 0.207734, "process_mem_max_rss": "100188", "process_out_blocks": "0", "process_user_time": 1.728429}
[0m15:43:08.656580 [debug] [MainThread]: Command `dbt run` failed at 15:43:08.656484 after 0.71 seconds
[0m15:43:08.657039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c8429a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a8a9580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a8900a0>]}
[0m15:43:08.657476 [debug] [MainThread]: Flushing usage events
[0m15:43:09.234204 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:45:04.518574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ce0ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8bf29580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8bf29520>]}


============================== 15:45:04.523119 | 3989c0a5-e6db-41c7-a823-d26f5c87d108 ==============================
[0m15:45:04.523119 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:45:04.523721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m15:45:04.632028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b4b9a60>]}
[0m15:45:04.664300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8bfbb220>]}
[0m15:45:04.665132 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:45:04.728399 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m15:45:04.837399 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:45:04.838085 [debug] [MainThread]: Partial parsing: updated file: homework://models/mart/iris_processed.sql
[0m15:45:05.087509 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m15:45:05.095881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ad18f10>]}
[0m15:45:05.159209 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:45:05.163880 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:45:05.175230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ad49280>]}
[0m15:45:05.175770 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m15:45:05.176214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ad55310>]}
[0m15:45:05.177317 [info ] [MainThread]: 
[0m15:45:05.177708 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:45:05.178096 [info ] [MainThread]: 
[0m15:45:05.178589 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:45:05.179403 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m15:45:05.201534 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m15:45:05.202102 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m15:45:05.202487 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:45:05.213281 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m15:45:05.214304 [debug] [ThreadPool]: On list_analytics: Close
[0m15:45:05.217523 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m15:45:05.221880 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:45:05.222341 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m15:45:05.222714 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:45:05.231158 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m15:45:05.231648 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m15:45:05.232051 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m15:45:05.235918 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m15:45:05.236883 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m15:45:05.237386 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m15:45:05.240757 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.241235 [debug] [MainThread]: On master: BEGIN
[0m15:45:05.241580 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:45:05.248777 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m15:45:05.249217 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.249642 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:45:05.253065 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m15:45:05.253991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8adc7fa0>]}
[0m15:45:05.254500 [debug] [MainThread]: On master: ROLLBACK
[0m15:45:05.254986 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.255347 [debug] [MainThread]: On master: BEGIN
[0m15:45:05.255889 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m15:45:05.256290 [debug] [MainThread]: On master: COMMIT
[0m15:45:05.256638 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.256980 [debug] [MainThread]: On master: COMMIT
[0m15:45:05.257416 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:45:05.257772 [debug] [MainThread]: On master: Close
[0m15:45:05.260603 [debug] [Thread-1  ]: Began running node model.homework.iris_processed
[0m15:45:05.261268 [info ] [Thread-1  ]: 1 of 1 START sql table model analytics.iris_processed .......................... [RUN]
[0m15:45:05.261766 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.iris_processed)
[0m15:45:05.262225 [debug] [Thread-1  ]: Began compiling node model.homework.iris_processed
[0m15:45:05.274661 [debug] [Thread-1  ]: Using postgres connection "model.homework.iris_processed"
[0m15:45:05.275133 [debug] [Thread-1  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m15:45:05.275539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:45:05.283027 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "analytics.stg_iris" does not exist
LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                             ^

[0m15:45:05.284757 [debug] [Thread-1  ]: On model.homework.iris_processed: Close
[0m15:45:05.286828 [debug] [Thread-1  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:45:05.288104 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3989c0a5-e6db-41c7-a823-d26f5c87d108', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8cc70fd0>]}
[0m15:45:05.288722 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.03s]
[0m15:45:05.289245 [debug] [Thread-1  ]: Finished running node model.homework.iris_processed
[0m15:45:05.289727 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^.
[0m15:45:05.290794 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.291178 [debug] [MainThread]: On master: BEGIN
[0m15:45:05.291569 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:45:05.298765 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m15:45:05.299214 [debug] [MainThread]: On master: COMMIT
[0m15:45:05.299583 [debug] [MainThread]: Using postgres connection "master"
[0m15:45:05.299931 [debug] [MainThread]: On master: COMMIT
[0m15:45:05.300388 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:45:05.300756 [debug] [MainThread]: On master: Close
[0m15:45:05.301205 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:45:05.301558 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m15:45:05.301937 [info ] [MainThread]: 
[0m15:45:05.302331 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.12 seconds (0.12s).
[0m15:45:05.302884 [debug] [MainThread]: Command end result
[0m15:45:05.333548 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m15:45:05.335084 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m15:45:05.339054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m15:45:05.339427 [info ] [MainThread]: 
[0m15:45:05.339837 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:45:05.340205 [info ] [MainThread]: 
[0m15:45:05.340595 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  relation "analytics.stg_iris" does not exist
  LINE 3: ...t(0.5) within group (order by sepal_length ) from "analytics...
                                                               ^
[0m15:45:05.340976 [info ] [MainThread]: 
[0m15:45:05.341334 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:45:05.342050 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.85691786, "process_in_blocks": "0", "process_kernel_time": 0.151967, "process_mem_max_rss": "112504", "process_out_blocks": "0", "process_user_time": 1.615925}
[0m15:45:05.342559 [debug] [MainThread]: Command `dbt run` failed at 15:45:05.342501 after 0.86 seconds
[0m15:45:05.342968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ce0ca30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b4b9a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8afc2910>]}
[0m15:45:05.343371 [debug] [MainThread]: Flushing usage events
[0m15:45:05.904293 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:02:35.500984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84f909d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff840ac550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff840ac4f0>]}


============================== 16:02:35.505519 | e1b9efa3-54bb-42be-a253-d1f6c74a1b17 ==============================
[0m16:02:35.505519 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:02:35.506066 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models --vars {"is_test": false, "data_date": "2025-05-10"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:02:35.632490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1b9efa3-54bb-42be-a253-d1f6c74a1b17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8363f1f0>]}
[0m16:02:35.664785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1b9efa3-54bb-42be-a253-d1f6c74a1b17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff835d9970>]}
[0m16:02:35.665532 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:02:35.728461 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m16:02:35.837458 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:02:35.838009 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:02:35.842151 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m16:02:35.862592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1b9efa3-54bb-42be-a253-d1f6c74a1b17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff83170130>]}
[0m16:02:35.954694 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:02:35.959762 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:02:35.971700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1b9efa3-54bb-42be-a253-d1f6c74a1b17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff830e7ca0>]}
[0m16:02:35.972256 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m16:02:35.972653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1b9efa3-54bb-42be-a253-d1f6c74a1b17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8329cac0>]}
[0m16:02:35.973190 [warn ] [MainThread]: The selection criterion 'models' does not match any enabled nodes
[0m16:02:35.973858 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m16:02:35.975111 [debug] [MainThread]: Command end result
[0m16:02:36.004533 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:02:36.005962 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:02:36.008308 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m16:02:36.009124 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.5414555, "process_in_blocks": "0", "process_kernel_time": 0.184982, "process_mem_max_rss": "97624", "process_out_blocks": "0", "process_user_time": 1.396971}
[0m16:02:36.009648 [debug] [MainThread]: Command `dbt run` succeeded at 16:02:36.009574 after 0.54 seconds
[0m16:02:36.010045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84f909d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8546bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff830e7ca0>]}
[0m16:02:36.010513 [debug] [MainThread]: Flushing usage events
[0m16:02:36.587869 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:04:14.666833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa30739d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa218f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa218f550>]}


============================== 16:04:14.671530 | 49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf ==============================
[0m16:04:14.671530 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:04:14.672079 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/dbt', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m16:04:14.781614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2209ee0>]}
[0m16:04:14.813092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2ee2220>]}
[0m16:04:14.813823 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:04:14.876644 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m16:04:14.987624 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:04:14.988132 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:04:14.992411 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m16:04:15.013915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1253130>]}
[0m16:04:15.116482 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:04:15.121367 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:04:15.132680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa172f430>]}
[0m16:04:15.133335 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m16:04:15.133898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49b30ac0-9a8e-4440-ae8b-0f83d97e9ecf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa13860a0>]}
[0m16:04:15.134779 [warn ] [MainThread]: The selection criterion 'models' does not match any enabled nodes
[0m16:04:15.135587 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m16:04:15.137042 [debug] [MainThread]: Command end result
[0m16:04:15.168201 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:04:15.169775 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:04:15.172177 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m16:04:15.172929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.53969514, "process_in_blocks": "0", "process_kernel_time": 0.133875, "process_mem_max_rss": "97640", "process_out_blocks": "0", "process_user_time": 1.382033}
[0m16:04:15.173472 [debug] [MainThread]: Command `dbt run` succeeded at 16:04:15.173411 after 0.54 seconds
[0m16:04:15.173903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa30739d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2f46760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa172f490>]}
[0m16:04:15.174299 [debug] [MainThread]: Flushing usage events
[0m16:04:15.743918 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:05:47.571409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb172f970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb084b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb084b430>]}


============================== 16:05:47.578933 | e76f9841-e19a-49c8-96c6-275604e3f05d ==============================
[0m16:05:47.578933 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:05:47.579885 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m16:05:47.712382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2968550>]}
[0m16:05:47.747545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb08e8400>]}
[0m16:05:47.748488 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:05:47.814697 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m16:05:47.930951 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:05:47.931543 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:05:47.936583 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m16:05:47.974330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf90f130>]}
[0m16:05:48.113472 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:05:48.118645 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:05:48.132154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf8d4610>]}
[0m16:05:48.132908 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m16:05:48.133535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafa40550>]}
[0m16:05:48.135482 [info ] [MainThread]: 
[0m16:05:48.136727 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:05:48.146648 [info ] [MainThread]: 
[0m16:05:48.148914 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:05:48.152479 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m16:05:48.189441 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m16:05:48.190028 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m16:05:48.190449 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:05:48.202991 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m16:05:48.204171 [debug] [ThreadPool]: On list_analytics: Close
[0m16:05:48.205313 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m16:05:48.209720 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m16:05:48.210389 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m16:05:48.211123 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:05:48.218699 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m16:05:48.219339 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m16:05:48.219962 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m16:05:48.223509 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m16:05:48.224582 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m16:05:48.225151 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m16:05:48.229081 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.229748 [debug] [MainThread]: On master: BEGIN
[0m16:05:48.230218 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:05:48.238310 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m16:05:48.238877 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.239327 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:05:48.243180 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m16:05:48.244339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafdd2b20>]}
[0m16:05:48.244904 [debug] [MainThread]: On master: ROLLBACK
[0m16:05:48.245512 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.246058 [debug] [MainThread]: On master: BEGIN
[0m16:05:48.246696 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m16:05:48.247107 [debug] [MainThread]: On master: COMMIT
[0m16:05:48.247483 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.247882 [debug] [MainThread]: On master: COMMIT
[0m16:05:48.248331 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:05:48.248719 [debug] [MainThread]: On master: Close
[0m16:05:48.252380 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m16:05:48.253159 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m16:05:48.253701 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m16:05:48.254132 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m16:05:48.261580 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m16:05:48.264857 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m16:05:48.288865 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m16:05:48.291370 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:05:48.291794 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m16:05:48.292190 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:05:48.300249 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m16:05:48.300905 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:05:48.301368 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    species
from source
  );
[0m16:05:48.306399 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m16:05:48.311419 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:05:48.312072 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m16:05:48.312900 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:05:48.322295 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m16:05:48.322994 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:05:48.323520 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m16:05:48.324653 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m16:05:48.329282 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m16:05:48.332535 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:05:48.333028 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m16:05:48.333710 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.000 seconds
[0m16:05:48.335694 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m16:05:48.337131 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaede1d90>]}
[0m16:05:48.337956 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.08s]
[0m16:05:48.338614 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m16:05:48.339400 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m16:05:48.340094 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m16:05:48.340765 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m16:05:48.341217 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m16:05:48.359704 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.360526 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.361136 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:05:48.371716 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.011 seconds
[0m16:05:48.373153 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.373603 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.374566 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.375569 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.376121 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.377189 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.382396 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.382888 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.383477 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.384488 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.384883 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.385658 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.386954 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.387499 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.388242 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.389934 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.390358 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.390939 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.391936 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.392332 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.392984 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.394193 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.394774 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.395588 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.397316 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.397763 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.398335 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.399357 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.399785 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.400338 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.401299 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.401699 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:05:48.402600 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.409336 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.409907 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m16:05:48.410952 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.412477 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.412987 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m16:05:48.413703 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.414915 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.415328 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m16:05:48.415895 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.417140 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.417615 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m16:05:48.418163 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:05:48.438707 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.439445 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m16:05:48.440136 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m16:05:48.440573 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.441011 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m16:05:48.441963 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m16:05:48.445537 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m16:05:48.447286 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m16:05:48.461768 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m16:05:48.463801 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:05:48.464492 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m16:05:48.466723 [debug] [Thread-3  ]: Postgres adapter: Postgres error: function log(integer, double precision) does not exist
LINE 294:         else log(10, sepal_length + 0)
                       ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

[0m16:05:48.467228 [debug] [Thread-3  ]: On model.homework.iris_processed: ROLLBACK
[0m16:05:48.467907 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m16:05:48.469653 [debug] [Thread-3  ]: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m16:05:48.470292 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e76f9841-e19a-49c8-96c6-275604e3f05d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb18ee940>]}
[0m16:05:48.470964 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model analytics.iris_processed ................. [[31mERROR[0m in 0.13s]
[0m16:05:48.471492 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m16:05:48.472040 [debug] [Thread-7  ]: Marking all children of 'model.homework.iris_processed' to be skipped because of status 'error'.  Reason: Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql.
[0m16:05:48.473212 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.473617 [debug] [MainThread]: On master: BEGIN
[0m16:05:48.474002 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:05:48.482618 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m16:05:48.483125 [debug] [MainThread]: On master: COMMIT
[0m16:05:48.483430 [debug] [MainThread]: Using postgres connection "master"
[0m16:05:48.483724 [debug] [MainThread]: On master: COMMIT
[0m16:05:48.484126 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:05:48.484460 [debug] [MainThread]: On master: Close
[0m16:05:48.485104 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:05:48.485658 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m16:05:48.486100 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m16:05:48.486540 [info ] [MainThread]: 
[0m16:05:48.487010 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m16:05:48.487736 [debug] [MainThread]: Command end result
[0m16:05:48.520741 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:05:48.522475 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:05:48.527437 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m16:05:48.527886 [info ] [MainThread]: 
[0m16:05:48.528304 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:05:48.528700 [info ] [MainThread]: 
[0m16:05:48.529102 [error] [MainThread]:   Database Error in model iris_processed (models/mart/iris_processed.sql)
  function log(integer, double precision) does not exist
  LINE 294:         else log(10, sepal_length + 0)
                         ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled code at target/run/homework/models/mart/iris_processed.sql
[0m16:05:48.529473 [info ] [MainThread]: 
[0m16:05:48.529864 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m16:05:48.530665 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0150309, "process_in_blocks": "0", "process_kernel_time": 0.232852, "process_mem_max_rss": "108020", "process_out_blocks": "0", "process_user_time": 1.769269}
[0m16:05:48.531346 [debug] [MainThread]: Command `dbt run` failed at 16:05:48.531236 after 1.02 seconds
[0m16:05:48.532042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb172f970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf8d4610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafd25d90>]}
[0m16:05:48.532601 [debug] [MainThread]: Flushing usage events
[0m16:05:49.089810 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:10:07.768883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d4c4a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5e0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c5e04f0>]}


============================== 16:10:07.773878 | 2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c ==============================
[0m16:10:07.773878 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:10:07.774469 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-10"}', 'send_anonymous_usage_stats': 'True'}
[0m16:10:07.902435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c687f10>]}
[0m16:10:07.935315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d26ef70>]}
[0m16:10:07.936081 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:10:07.999528 [debug] [MainThread]: checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff, vars: {'data_date': '2025-05-10', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m16:10:08.134712 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:10:08.135398 [debug] [MainThread]: Partial parsing: updated file: homework://models/staging/stg_iris.sql
[0m16:10:08.340117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m16:10:08.348434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7aea3130>]}
[0m16:10:08.411007 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:10:08.415404 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:10:08.426211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ae380d0>]}
[0m16:10:08.426802 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m16:10:08.427214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ae38e50>]}
[0m16:10:08.428490 [info ] [MainThread]: 
[0m16:10:08.428892 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:10:08.429257 [info ] [MainThread]: 
[0m16:10:08.429772 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:10:08.432497 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m16:10:08.456983 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m16:10:08.457558 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m16:10:08.458144 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:10:08.470649 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m16:10:08.472149 [debug] [ThreadPool]: On list_analytics: Close
[0m16:10:08.473678 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m16:10:08.478343 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m16:10:08.478937 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m16:10:08.479415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:10:08.487293 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m16:10:08.487868 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m16:10:08.488267 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m16:10:08.493224 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m16:10:08.494584 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m16:10:08.495289 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m16:10:08.499216 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.499795 [debug] [MainThread]: On master: BEGIN
[0m16:10:08.500262 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:10:08.509042 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m16:10:08.509633 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.510296 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:10:08.517599 [debug] [MainThread]: SQL status: SELECT 1 in 0.007 seconds
[0m16:10:08.518888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a306f10>]}
[0m16:10:08.519487 [debug] [MainThread]: On master: ROLLBACK
[0m16:10:08.520235 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.520720 [debug] [MainThread]: On master: BEGIN
[0m16:10:08.521419 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m16:10:08.521844 [debug] [MainThread]: On master: COMMIT
[0m16:10:08.522328 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.522760 [debug] [MainThread]: On master: COMMIT
[0m16:10:08.523285 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:10:08.523740 [debug] [MainThread]: On master: Close
[0m16:10:08.526978 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m16:10:08.527687 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m16:10:08.528293 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m16:10:08.528737 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m16:10:08.534499 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m16:10:08.544015 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m16:10:08.587092 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m16:10:08.598953 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.599470 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m16:10:08.599894 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:10:08.607573 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m16:10:08.608057 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.608498 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m16:10:08.613516 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m16:10:08.618843 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.619627 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m16:10:08.620898 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:10:08.624105 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.624786 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m16:10:08.625560 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:10:08.636981 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m16:10:08.637732 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.638200 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m16:10:08.639917 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m16:10:08.644751 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m16:10:08.648403 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m16:10:08.649041 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m16:10:08.650684 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m16:10:08.652497 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m16:10:08.653772 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7a2dd070>]}
[0m16:10:08.654547 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.12s]
[0m16:10:08.655155 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m16:10:08.655986 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m16:10:08.656680 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m16:10:08.657243 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m16:10:08.657652 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m16:10:08.677010 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.677681 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.678232 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:10:08.688215 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.010 seconds
[0m16:10:08.690032 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.690880 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.692091 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.693493 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.693995 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.694819 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.699543 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.700460 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.701412 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.702734 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.703253 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.704173 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.705437 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.706057 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.706961 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.708936 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.709547 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.710610 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.711958 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.712548 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.713699 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.714997 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.715538 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.716406 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.718134 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.718798 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.719696 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.720943 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.721544 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.722288 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.723462 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.724016 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m16:10:08.724901 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.731767 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.732246 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m16:10:08.733104 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.734614 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.735112 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m16:10:08.735884 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.737388 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.737917 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m16:10:08.738710 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.740191 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.740735 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m16:10:08.741481 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m16:10:08.761578 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.762220 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m16:10:08.762886 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m16:10:08.763454 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.764005 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m16:10:08.765097 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m16:10:08.768517 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m16:10:08.770302 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m16:10:08.785663 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m16:10:08.787357 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.788009 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m16:10:08.803943 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.015 seconds
[0m16:10:08.809208 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.809882 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m16:10:08.810654 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:10:08.811778 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m16:10:08.812194 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.812615 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m16:10:08.813754 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m16:10:08.815762 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m16:10:08.817595 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m16:10:08.818031 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m16:10:08.818588 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.000 seconds
[0m16:10:08.819578 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m16:10:08.820203 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2fc17a6a-3b9c-4452-90bf-fe2c74a7a53c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d692910>]}
[0m16:10:08.820901 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.16s]
[0m16:10:08.821574 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m16:10:08.824187 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.824701 [debug] [MainThread]: On master: BEGIN
[0m16:10:08.825082 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:10:08.832891 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m16:10:08.833489 [debug] [MainThread]: On master: COMMIT
[0m16:10:08.834052 [debug] [MainThread]: Using postgres connection "master"
[0m16:10:08.834571 [debug] [MainThread]: On master: COMMIT
[0m16:10:08.835137 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:10:08.835557 [debug] [MainThread]: On master: Close
[0m16:10:08.836079 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:10:08.836514 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m16:10:08.836963 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m16:10:08.837506 [info ] [MainThread]: 
[0m16:10:08.837936 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m16:10:08.838723 [debug] [MainThread]: Command end result
[0m16:10:08.869713 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m16:10:08.871521 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m16:10:08.876654 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m16:10:08.877094 [info ] [MainThread]: 
[0m16:10:08.877691 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:10:08.878246 [info ] [MainThread]: 
[0m16:10:08.878771 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:10:08.879639 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.1460493, "process_in_blocks": "0", "process_kernel_time": 0.250335, "process_mem_max_rss": "113132", "process_out_blocks": "0", "process_user_time": 1.851673}
[0m16:10:08.880163 [debug] [MainThread]: Command `dbt run` succeeded at 16:10:08.880105 after 1.15 seconds
[0m16:10:08.880560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d4c4a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ae6c4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d26ef70>]}
[0m16:10:08.880980 [debug] [MainThread]: Flushing usage events
[0m16:10:09.428662 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:07:48.349480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0d309a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafe4c430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafe4c3d0>]}


============================== 09:07:48.354954 | 563bbb99-4732-4608-8926-f38a395b3b79 ==============================
[0m09:07:48.354954 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:07:48.355594 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:07:48.493363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafe87820>]}
[0m09:07:48.529647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0021dc0>]}
[0m09:07:48.530609 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:07:48.595339 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:07:48.664458 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:07:48.665125 [debug] [MainThread]: previous checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, current checksum: a0841b9e95e4ad17bec1bf740851d7b012e6cf6b937585e2bd7e396b95b8b6ff
[0m09:07:48.665585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb056e880>]}
[0m09:07:49.611039 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:07:49.620021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf10e130>]}
[0m09:07:49.692130 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:07:49.697357 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:07:49.710367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae426190>]}
[0m09:07:49.710905 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:07:49.712000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae4266d0>]}
[0m09:07:49.713303 [info ] [MainThread]: 
[0m09:07:49.713700 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:07:49.714006 [info ] [MainThread]: 
[0m09:07:49.714435 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:07:49.717727 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:07:49.744460 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:07:49.745342 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:07:49.745914 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:07:49.759321 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m09:07:49.760870 [debug] [ThreadPool]: On list_analytics: Close
[0m09:07:49.762284 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:07:49.768301 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:07:49.768949 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:07:49.769428 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:07:49.779194 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m09:07:49.780098 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:07:49.780832 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:07:49.786034 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.004 seconds
[0m09:07:49.787686 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:07:49.788581 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:07:49.793622 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:49.794381 [debug] [MainThread]: On master: BEGIN
[0m09:07:49.794852 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:07:49.803715 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m09:07:49.804588 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:49.805233 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:07:49.812198 [debug] [MainThread]: SQL status: SELECT 1 in 0.006 seconds
[0m09:07:49.814171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad92d0a0>]}
[0m09:07:49.815036 [debug] [MainThread]: On master: ROLLBACK
[0m09:07:49.815896 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:49.816479 [debug] [MainThread]: On master: BEGIN
[0m09:07:49.817279 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:07:49.817951 [debug] [MainThread]: On master: COMMIT
[0m09:07:49.818588 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:49.819137 [debug] [MainThread]: On master: COMMIT
[0m09:07:49.819829 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:07:49.820313 [debug] [MainThread]: On master: Close
[0m09:07:49.823864 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:07:49.824740 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:07:49.825494 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:07:49.826026 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:07:49.832637 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:07:49.834558 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:07:49.857376 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:07:49.859229 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.859773 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:07:49.860186 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:07:49.871560 [debug] [Thread-1  ]: SQL status: BEGIN in 0.011 seconds
[0m09:07:49.872108 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.872491 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:07:49.876469 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m09:07:49.881871 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.882364 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:07:49.883022 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:07:49.885529 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.894944 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:07:49.895752 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:07:49.906590 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:07:49.924240 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.926716 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:07:49.930755 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m09:07:49.938661 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:07:49.951228 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:07:49.952072 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:07:49.953990 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:07:49.956276 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:07:49.957636 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad8f81c0>]}
[0m09:07:49.958313 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.13s]
[0m09:07:49.958949 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:07:49.959737 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:07:49.960288 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:07:49.960893 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:07:49.961309 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:07:49.972622 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.973333 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.973863 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:07:49.984465 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.011 seconds
[0m09:07:49.985976 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.986511 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.987457 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:49.988554 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.989019 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.989713 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:49.991438 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.992033 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.992783 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:49.993917 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.994374 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.995062 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:49.996198 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.996693 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:49.997394 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:49.998980 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:49.999433 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.000261 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.001681 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.002229 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.003034 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.004403 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.005021 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.005886 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.007621 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.008147 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.008911 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.010145 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.010623 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.011340 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.012504 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.013026 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:07:50.013803 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.016196 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.016793 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:07:50.017619 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.019214 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.019795 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:07:50.020660 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.022217 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.022823 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:07:50.023766 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.025409 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.025897 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:07:50.026631 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:07:50.033240 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.034005 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:07:50.034638 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:07:50.035134 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.035644 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:07:50.036647 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m09:07:50.044001 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:07:50.046040 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:07:50.079319 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:07:50.082162 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.085145 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:07:50.107374 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.020 seconds
[0m09:07:50.115115 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.118118 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:07:50.120772 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:07:50.125324 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.127079 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:07:50.127897 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:07:50.129490 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:07:50.130699 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.133930 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:07:50.136150 [debug] [Thread-3  ]: SQL status: COMMIT in 0.002 seconds
[0m09:07:50.140798 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:07:50.146401 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:07:50.147204 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:07:50.161075 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.013 seconds
[0m09:07:50.163472 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:07:50.169751 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '563bbb99-4732-4608-8926-f38a395b3b79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0c02850>]}
[0m09:07:50.170846 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.21s]
[0m09:07:50.171641 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:07:50.174907 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:50.175516 [debug] [MainThread]: On master: BEGIN
[0m09:07:50.176045 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:07:50.188004 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m09:07:50.188779 [debug] [MainThread]: On master: COMMIT
[0m09:07:50.189259 [debug] [MainThread]: Using postgres connection "master"
[0m09:07:50.189688 [debug] [MainThread]: On master: COMMIT
[0m09:07:50.190644 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:07:50.192961 [debug] [MainThread]: On master: Close
[0m09:07:50.193625 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:07:50.194262 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:07:50.195529 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:07:50.196256 [info ] [MainThread]: 
[0m09:07:50.197005 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m09:07:50.197867 [debug] [MainThread]: Command end result
[0m09:07:50.245048 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:07:50.247040 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:07:50.253944 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:07:50.254468 [info ] [MainThread]: 
[0m09:07:50.255072 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:07:50.255658 [info ] [MainThread]: 
[0m09:07:50.256277 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:07:50.258111 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.9443936, "process_in_blocks": "0", "process_kernel_time": 0.252446, "process_mem_max_rss": "113444", "process_out_blocks": "0", "process_user_time": 2.594417}
[0m09:07:50.259827 [debug] [MainThread]: Command `dbt run` succeeded at 09:07:50.259664 after 1.95 seconds
[0m09:07:50.268322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0d309a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae426190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb13f3730>]}
[0m09:07:50.272553 [debug] [MainThread]: Flushing usage events
[0m09:07:50.954161 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:08:38.695110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a21e970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8933a430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8933a3d0>]}


============================== 09:08:38.699860 | c8859ea1-163d-4fcd-9061-5fca429ddfdc ==============================
[0m09:08:38.699860 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:08:38.700423 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'send_anonymous_usage_stats': 'True'}
[0m09:08:38.810149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b457550>]}
[0m09:08:38.842046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88882a30>]}
[0m09:08:38.842791 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:08:38.905115 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:08:39.007641 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:08:39.008140 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:08:39.012030 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:08:39.032054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff883fe130>]}
[0m09:08:39.130703 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:08:39.135224 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:08:39.145894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff883c3100>]}
[0m09:08:39.146477 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:08:39.146943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88604b50>]}
[0m09:08:39.148298 [info ] [MainThread]: 
[0m09:08:39.148708 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:08:39.149083 [info ] [MainThread]: 
[0m09:08:39.149578 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:08:39.152436 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:08:39.175124 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:08:39.175768 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:08:39.176170 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:08:39.187253 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m09:08:39.188244 [debug] [ThreadPool]: On list_analytics: Close
[0m09:08:39.189251 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:08:39.193473 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:08:39.193914 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:08:39.194228 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:08:39.201136 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m09:08:39.201522 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:08:39.201995 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:08:39.204994 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.002 seconds
[0m09:08:39.206039 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:08:39.206566 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:08:39.210169 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.210670 [debug] [MainThread]: On master: BEGIN
[0m09:08:39.211046 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:08:39.217884 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:08:39.218399 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.218822 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:08:39.223562 [debug] [MainThread]: SQL status: SELECT 1 in 0.004 seconds
[0m09:08:39.224613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff883bbdf0>]}
[0m09:08:39.225105 [debug] [MainThread]: On master: ROLLBACK
[0m09:08:39.225616 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.225994 [debug] [MainThread]: On master: BEGIN
[0m09:08:39.226625 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:08:39.227076 [debug] [MainThread]: On master: COMMIT
[0m09:08:39.227481 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.227853 [debug] [MainThread]: On master: COMMIT
[0m09:08:39.228307 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:08:39.228681 [debug] [MainThread]: On master: Close
[0m09:08:39.231496 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:08:39.232166 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:08:39.232698 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:08:39.233116 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:08:39.238401 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:08:39.239573 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:08:39.261026 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:08:39.262315 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.262750 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:08:39.263138 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:08:39.270998 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m09:08:39.271560 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.272084 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:08:39.275565 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m09:08:39.280490 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.280998 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:08:39.281702 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:08:39.283974 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.284475 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:08:39.285084 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:08:39.294966 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:08:39.295480 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.295912 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:08:39.296986 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:08:39.301272 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:08:39.304298 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:08:39.304801 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:08:39.306228 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:08:39.308193 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:08:39.309627 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff878c7220>]}
[0m09:08:39.310265 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.08s]
[0m09:08:39.310837 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:08:39.311589 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:08:39.312169 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:08:39.312698 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:08:39.313084 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:08:39.331095 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.331673 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.332088 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:08:39.341208 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.009 seconds
[0m09:08:39.342610 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.343115 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.343959 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.345159 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.345697 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.346459 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.350895 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.351337 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.352031 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.353032 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.353435 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.354059 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.355075 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.355482 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.356074 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.357528 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.357947 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.358548 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.359522 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.359936 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.360607 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.361612 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.362013 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.362616 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.364020 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.364415 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.365008 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.365978 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.366367 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.366955 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.367916 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.368365 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:08:39.368929 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.375318 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.375757 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:08:39.376373 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.377532 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.377934 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:08:39.378529 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.379745 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.380152 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:08:39.380738 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.381910 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.382300 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:08:39.382885 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:08:39.401786 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.402247 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:08:39.402812 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:08:39.403224 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.403632 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:08:39.404434 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.000 seconds
[0m09:08:39.407327 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:08:39.408628 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:08:39.422015 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:08:39.423377 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.424001 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:08:39.439231 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.015 seconds
[0m09:08:39.444125 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.444590 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:08:39.445259 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:08:39.447377 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.447802 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:08:39.448332 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:08:39.449473 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:08:39.449896 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.450266 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:08:39.451441 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:08:39.453326 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:08:39.455056 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:08:39.455445 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:08:39.460181 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.004 seconds
[0m09:08:39.461350 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:08:39.461963 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8859ea1-163d-4fcd-9061-5fca429ddfdc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff846e5940>]}
[0m09:08:39.462560 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.15s]
[0m09:08:39.463121 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:08:39.464277 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.464699 [debug] [MainThread]: On master: BEGIN
[0m09:08:39.465039 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:08:39.472051 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:08:39.472483 [debug] [MainThread]: On master: COMMIT
[0m09:08:39.472827 [debug] [MainThread]: Using postgres connection "master"
[0m09:08:39.473139 [debug] [MainThread]: On master: COMMIT
[0m09:08:39.473538 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:08:39.473931 [debug] [MainThread]: On master: Close
[0m09:08:39.474401 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:08:39.474767 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:08:39.475173 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:08:39.475567 [info ] [MainThread]: 
[0m09:08:39.476016 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m09:08:39.476844 [debug] [MainThread]: Command end result
[0m09:08:39.506230 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:08:39.507837 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:08:39.512287 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:08:39.512682 [info ] [MainThread]: 
[0m09:08:39.513120 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:08:39.513478 [info ] [MainThread]: 
[0m09:08:39.513858 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:08:39.514587 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.85312, "process_in_blocks": "0", "process_kernel_time": 0.155166, "process_mem_max_rss": "107900", "process_out_blocks": "0", "process_user_time": 1.599328}
[0m09:08:39.515102 [debug] [MainThread]: Command `dbt run` succeeded at 09:08:39.515040 after 0.85 seconds
[0m09:08:39.515484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a21e970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b457550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b2470d0>]}
[0m09:08:39.515895 [debug] [MainThread]: Flushing usage events
[0m09:08:40.097458 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:09:50.695081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1439970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0555490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0555430>]}


============================== 09:09:50.700480 | 54d30ec4-d16a-49b6-af13-9cc4b576a0a6 ==============================
[0m09:09:50.700480 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:09:50.701155 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:09:50.825528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2672550>]}
[0m09:09:50.858240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa05f2400>]}
[0m09:09:50.858976 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:09:50.924946 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:09:51.078558 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:09:51.079565 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:09:51.085504 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:09:51.119352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f619130>]}
[0m09:09:51.246921 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:09:51.251808 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:09:51.264164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f5dd610>]}
[0m09:09:51.264756 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:09:51.265176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f819ac0>]}
[0m09:09:51.266492 [info ] [MainThread]: 
[0m09:09:51.266905 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:09:51.267279 [info ] [MainThread]: 
[0m09:09:51.267773 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:09:51.270740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:09:51.296651 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:09:51.297314 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:09:51.297730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:51.310043 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m09:09:51.311160 [debug] [ThreadPool]: On list_analytics: Close
[0m09:09:51.312196 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:09:51.318564 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:09:51.319312 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:09:51.319809 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:09:51.327925 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m09:09:51.328674 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:09:51.329452 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:09:51.333004 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m09:09:51.334169 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:09:51.334744 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:09:51.338753 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.339278 [debug] [MainThread]: On master: BEGIN
[0m09:09:51.339709 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:09:51.347130 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:09:51.347694 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.348257 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:09:51.353461 [debug] [MainThread]: SQL status: SELECT 1 in 0.005 seconds
[0m09:09:51.354747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9fadcb20>]}
[0m09:09:51.355527 [debug] [MainThread]: On master: ROLLBACK
[0m09:09:51.356363 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.356974 [debug] [MainThread]: On master: BEGIN
[0m09:09:51.357623 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:09:51.358055 [debug] [MainThread]: On master: COMMIT
[0m09:09:51.358444 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.358807 [debug] [MainThread]: On master: COMMIT
[0m09:09:51.359299 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:09:51.359717 [debug] [MainThread]: On master: Close
[0m09:09:51.362752 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:09:51.363374 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:09:51.363873 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:09:51.364385 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:09:51.369958 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:09:51.372432 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:09:51.396869 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:09:51.398422 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.398956 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:09:51.399431 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:09:51.407935 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m09:09:51.408482 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.408981 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:09:51.413461 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.004 seconds
[0m09:09:51.418472 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.419046 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:09:51.420097 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m09:09:51.422776 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.423302 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:09:51.424060 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:09:51.434519 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:09:51.435071 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.435504 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:09:51.436741 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:09:51.441477 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:09:51.444554 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:09:51.445029 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:09:51.446448 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:09:51.448407 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:09:51.450011 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2652790>]}
[0m09:09:51.450778 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.09s]
[0m09:09:51.451401 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:09:51.452528 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:09:51.453107 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:09:51.453655 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:09:51.454095 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:09:51.474059 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.474615 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.475138 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:09:51.487744 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.012 seconds
[0m09:09:51.490037 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.490668 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.491680 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.493115 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.493659 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.494403 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.499051 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.499551 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.500281 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.501612 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.502154 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.503165 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.504408 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.504834 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.505519 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.507160 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.507629 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.508323 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.509560 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.510003 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.510760 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.511810 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.512211 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.512855 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.514408 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.514960 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.515853 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.517156 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.517665 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.518517 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.519885 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.520346 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:09:51.521074 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.528012 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.528506 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:09:51.529169 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.530443 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.530857 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:09:51.531473 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.532675 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.533076 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:09:51.533807 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.534974 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.535381 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:09:51.536063 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:09:51.556081 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.556628 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:09:51.557398 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:09:51.558034 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.558482 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:09:51.559452 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.001 seconds
[0m09:09:51.562819 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:09:51.563968 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:09:51.578617 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:09:51.579827 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.580492 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:09:51.596412 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.015 seconds
[0m09:09:51.601753 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.602245 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:09:51.602963 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:09:51.605234 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.605657 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:09:51.606216 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:09:51.607391 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:09:51.607799 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.608219 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:09:51.609817 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:09:51.611859 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:09:51.613691 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:09:51.614121 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:09:51.619155 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.005 seconds
[0m09:09:51.620288 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:09:51.620938 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54d30ec4-d16a-49b6-af13-9cc4b576a0a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9c102970>]}
[0m09:09:51.621555 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.17s]
[0m09:09:51.622051 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:09:51.623064 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.623514 [debug] [MainThread]: On master: BEGIN
[0m09:09:51.623825 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:09:51.631289 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:09:51.631901 [debug] [MainThread]: On master: COMMIT
[0m09:09:51.632347 [debug] [MainThread]: Using postgres connection "master"
[0m09:09:51.632650 [debug] [MainThread]: On master: COMMIT
[0m09:09:51.633127 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:09:51.633621 [debug] [MainThread]: On master: Close
[0m09:09:51.634175 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:09:51.634731 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:09:51.635208 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:09:51.635630 [info ] [MainThread]: 
[0m09:09:51.636034 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m09:09:51.636765 [debug] [MainThread]: Command end result
[0m09:09:51.668830 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:09:51.670562 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:09:51.675079 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:09:51.675480 [info ] [MainThread]: 
[0m09:09:51.675920 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:09:51.676302 [info ] [MainThread]: 
[0m09:09:51.676672 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:09:51.677441 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0196873, "process_in_blocks": "0", "process_kernel_time": 0.199599, "process_mem_max_rss": "107584", "process_out_blocks": "0", "process_user_time": 1.752606}
[0m09:09:51.677939 [debug] [MainThread]: Command `dbt run` succeeded at 09:09:51.677881 after 1.02 seconds
[0m09:09:51.678334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1439970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2672550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f5d1eb0>]}
[0m09:09:51.678907 [debug] [MainThread]: Flushing usage events
[0m09:09:52.292714 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:12:04.136668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938d89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff929f4580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff929f4520>]}


============================== 09:12:04.141711 | 8f744d63-59b1-469c-9ad3-b143e526fb05 ==============================
[0m09:12:04.141711 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:12:04.142275 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:12:04.267659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94b1a8e0>]}
[0m09:12:04.303858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92a9cb20>]}
[0m09:12:04.304956 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:12:04.370850 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:12:04.478763 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:12:04.479247 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:12:04.483196 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:12:04.503508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91ab8130>]}
[0m09:12:04.594300 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:12:04.599110 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:12:04.610449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91a74610>]}
[0m09:12:04.610944 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:12:04.611370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91befbe0>]}
[0m09:12:04.612607 [info ] [MainThread]: 
[0m09:12:04.612991 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:12:04.613361 [info ] [MainThread]: 
[0m09:12:04.613828 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:12:04.616544 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:12:04.642636 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:12:04.643188 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:12:04.643598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:12:04.654252 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m09:12:04.655309 [debug] [ThreadPool]: On list_analytics: Close
[0m09:12:04.656400 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:12:04.660655 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:12:04.661176 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:12:04.661571 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:12:04.668801 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m09:12:04.669252 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:12:04.669652 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:12:04.673305 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m09:12:04.674230 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:12:04.674718 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:12:04.678300 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.678794 [debug] [MainThread]: On master: BEGIN
[0m09:12:04.679165 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:12:04.686109 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:12:04.686643 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.687146 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:12:04.692556 [debug] [MainThread]: SQL status: SELECT 1 in 0.005 seconds
[0m09:12:04.693769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91ab83d0>]}
[0m09:12:04.694259 [debug] [MainThread]: On master: ROLLBACK
[0m09:12:04.694792 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.695172 [debug] [MainThread]: On master: BEGIN
[0m09:12:04.696504 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:12:04.697259 [debug] [MainThread]: On master: COMMIT
[0m09:12:04.697658 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.698179 [debug] [MainThread]: On master: COMMIT
[0m09:12:04.698818 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:12:04.699250 [debug] [MainThread]: On master: Close
[0m09:12:04.702339 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:12:04.702957 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:12:04.703485 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:12:04.703907 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:12:04.709287 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:12:04.710583 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:12:04.732322 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:12:04.733700 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.734107 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:12:04.734532 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:12:04.741947 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m09:12:04.742418 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.742819 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:12:04.746231 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m09:12:04.750845 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.751303 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:12:04.751971 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:04.754109 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.754523 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:12:04.755083 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:04.764687 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:12:04.765132 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.765523 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:12:04.766850 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:12:04.770877 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:12:04.773627 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:04.774047 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:12:04.775397 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:12:04.776992 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:12:04.778219 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90f801c0>]}
[0m09:12:04.778843 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.07s]
[0m09:12:04.779397 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:12:04.780207 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:12:04.780795 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:12:04.781342 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:12:04.781742 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:12:04.799923 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.800419 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.800813 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:12:04.810036 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.009 seconds
[0m09:12:04.811239 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.811671 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.812426 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.813433 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.813848 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.814477 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.818662 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.819088 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.819714 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.820722 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.821129 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.821763 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.822750 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.823140 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.823723 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.825134 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.825542 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.826120 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.827053 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.827455 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.828098 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.829073 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.829479 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.830045 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.831427 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.831815 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.832389 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.833332 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.833722 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.834289 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.835221 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.835614 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:04.836186 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.842481 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.842905 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:04.843562 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.844708 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.845100 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:04.845677 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.846828 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.847216 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:04.847789 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.848905 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.849294 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:04.849865 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:04.868540 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.868983 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:12:04.869526 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:12:04.869915 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.870327 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:12:04.871124 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.000 seconds
[0m09:12:04.874051 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:12:04.875213 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:12:04.889558 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:12:04.890847 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.891501 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:12:04.907018 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.015 seconds
[0m09:12:04.912083 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.912547 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:12:04.913245 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:04.915403 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.915821 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:12:04.916475 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:04.917650 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:12:04.918073 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.918461 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:12:04.919651 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:12:04.921571 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:12:04.923292 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:04.923728 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:12:04.933811 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.010 seconds
[0m09:12:04.934951 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:12:04.935584 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f744d63-59b1-469c-9ad3-b143e526fb05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90ec68e0>]}
[0m09:12:04.936167 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.15s]
[0m09:12:04.936702 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:12:04.937855 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.938370 [debug] [MainThread]: On master: BEGIN
[0m09:12:04.938777 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:12:04.946133 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:12:04.946607 [debug] [MainThread]: On master: COMMIT
[0m09:12:04.946987 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:04.947353 [debug] [MainThread]: On master: COMMIT
[0m09:12:04.948041 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:12:04.948521 [debug] [MainThread]: On master: Close
[0m09:12:04.949049 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:12:04.949559 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:12:04.950079 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:12:04.950601 [info ] [MainThread]: 
[0m09:12:04.951040 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m09:12:04.951841 [debug] [MainThread]: Command end result
[0m09:12:04.982387 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:12:04.984203 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:12:04.988812 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:12:04.989198 [info ] [MainThread]: 
[0m09:12:04.989646 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:12:04.990047 [info ] [MainThread]: 
[0m09:12:04.990457 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:12:04.991280 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.88950485, "process_in_blocks": "0", "process_kernel_time": 0.263039, "process_mem_max_rss": "107688", "process_out_blocks": "0", "process_user_time": 1.601508}
[0m09:12:04.991847 [debug] [MainThread]: Command `dbt run` succeeded at 09:12:04.991786 after 0.89 seconds
[0m09:12:04.992254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff938d89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93710460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91a74610>]}
[0m09:12:04.992668 [debug] [MainThread]: Flushing usage events
[0m09:12:05.677466 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:12:36.303872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3a6aa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2b86550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2b864f0>]}


============================== 09:12:36.308474 | 4551c95e-9430-47ff-be0c-b16203f7d6b2 ==============================
[0m09:12:36.308474 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:12:36.309024 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'profiles_dir': '/opt/airflow/dags/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:12:36.415759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2c2df10>]}
[0m09:12:36.447442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3815f70>]}
[0m09:12:36.448158 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:12:36.510269 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:12:36.618213 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:12:36.618743 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:12:36.622679 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:12:36.642925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1c4a130>]}
[0m09:12:36.734332 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:12:36.739005 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:12:36.749726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1bc0df0>]}
[0m09:12:36.750342 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:12:36.750736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1d77430>]}
[0m09:12:36.752077 [info ] [MainThread]: 
[0m09:12:36.752471 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:12:36.752847 [info ] [MainThread]: 
[0m09:12:36.753337 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:12:36.756251 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:12:36.779388 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:12:36.780059 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:12:36.780467 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:12:36.790763 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.010 seconds
[0m09:12:36.791886 [debug] [ThreadPool]: On list_analytics: Close
[0m09:12:36.793026 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:12:36.797335 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:12:36.797806 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:12:36.798179 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:12:36.805073 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m09:12:36.805517 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:12:36.805961 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:12:36.809198 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.003 seconds
[0m09:12:36.810220 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:12:36.810749 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:12:36.814287 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:36.814796 [debug] [MainThread]: On master: BEGIN
[0m09:12:36.815165 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:12:36.822697 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m09:12:36.823154 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:36.823585 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:12:36.829262 [debug] [MainThread]: SQL status: SELECT 1 in 0.005 seconds
[0m09:12:36.830361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1e79e80>]}
[0m09:12:36.830848 [debug] [MainThread]: On master: ROLLBACK
[0m09:12:36.831341 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:36.831720 [debug] [MainThread]: On master: BEGIN
[0m09:12:36.832285 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:12:36.832679 [debug] [MainThread]: On master: COMMIT
[0m09:12:36.833047 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:36.833405 [debug] [MainThread]: On master: COMMIT
[0m09:12:36.833860 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:12:36.834222 [debug] [MainThread]: On master: Close
[0m09:12:36.837039 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:12:36.837590 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:12:36.838187 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:12:36.838684 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:12:36.844416 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:12:36.846054 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:12:36.868601 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:12:36.870107 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.870540 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:12:36.871002 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:12:36.878383 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m09:12:36.878816 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.879230 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:12:36.882246 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m09:12:36.887130 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.887575 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:12:36.888270 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:36.890411 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.890846 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:12:36.891579 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:36.902046 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:12:36.902733 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.903226 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:12:36.904555 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:12:36.909082 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:12:36.912157 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:12:36.912643 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:12:36.913973 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:12:36.915783 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:12:36.917098 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1110220>]}
[0m09:12:36.917809 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.08s]
[0m09:12:36.918409 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:12:36.919243 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:12:36.919837 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:12:36.920359 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:12:36.920766 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:12:36.939151 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.939683 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.940111 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:12:36.950605 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.010 seconds
[0m09:12:36.951832 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.952271 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.953090 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.954069 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.954469 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.955095 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.959346 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.959776 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.960395 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.961392 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.961800 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.962396 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.963360 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.963779 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.964419 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.965849 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.966246 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.966848 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.967807 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.968197 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.968861 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.969822 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.970220 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.970806 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.972234 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.972651 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.973292 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.974255 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.974657 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.975230 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.976185 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.976569 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:12:36.977147 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.983471 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.983903 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:36.984492 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.985674 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.986077 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:36.986658 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.987810 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.988200 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:36.988796 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:36.989977 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:36.990366 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:12:36.990959 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:12:37.009810 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.010251 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:12:37.010787 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:12:37.011186 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.011576 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:12:37.012458 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.000 seconds
[0m09:12:37.015308 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:12:37.016475 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:12:37.029932 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:12:37.031208 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.031948 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:12:37.047207 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.014 seconds
[0m09:12:37.052227 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.052708 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:12:37.053394 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:37.055568 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.055992 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:12:37.056577 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:12:37.057771 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:12:37.058200 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.058592 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:12:37.059603 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:12:37.061509 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:12:37.063257 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:12:37.063669 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:12:37.068304 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.004 seconds
[0m09:12:37.069425 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:12:37.070055 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4551c95e-9430-47ff-be0c-b16203f7d6b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb073aa00>]}
[0m09:12:37.070664 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.15s]
[0m09:12:37.071192 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:12:37.072332 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:37.072799 [debug] [MainThread]: On master: BEGIN
[0m09:12:37.073200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:12:37.080467 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:12:37.080991 [debug] [MainThread]: On master: COMMIT
[0m09:12:37.081371 [debug] [MainThread]: Using postgres connection "master"
[0m09:12:37.081758 [debug] [MainThread]: On master: COMMIT
[0m09:12:37.082216 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:12:37.082584 [debug] [MainThread]: On master: Close
[0m09:12:37.083082 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:12:37.083467 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:12:37.083834 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:12:37.084236 [info ] [MainThread]: 
[0m09:12:37.084651 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m09:12:37.085365 [debug] [MainThread]: Command end result
[0m09:12:37.114295 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:12:37.115758 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:12:37.120285 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:12:37.120658 [info ] [MainThread]: 
[0m09:12:37.121083 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:12:37.121425 [info ] [MainThread]: 
[0m09:12:37.121788 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:12:37.122518 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8522487, "process_in_blocks": "0", "process_kernel_time": 0.145273, "process_mem_max_rss": "107712", "process_out_blocks": "0", "process_user_time": 1.58778}
[0m09:12:37.123028 [debug] [MainThread]: Command `dbt run` succeeded at 09:12:37.122970 after 0.85 seconds
[0m09:12:37.123433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3a6aa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb38a8f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1be9c70>]}
[0m09:12:37.123822 [debug] [MainThread]: Flushing usage events
[0m09:12:37.693341 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:14:41.838603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1cd0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0dec490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0dec430>]}


============================== 09:14:41.843393 | 48829bc6-87e3-4786-b83e-5697173d942b ==============================
[0m09:14:41.843393 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:14:41.843978 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:14:41.970723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2f09550>]}
[0m09:14:42.002711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0e89400>]}
[0m09:14:42.003454 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:14:42.067607 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:14:42.177992 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:14:42.178507 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:14:42.182421 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:14:42.202810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafeb0130>]}
[0m09:14:42.295247 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:14:42.300406 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:14:42.312132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafe74280>]}
[0m09:14:42.312694 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:14:42.313097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb006cac0>]}
[0m09:14:42.314392 [info ] [MainThread]: 
[0m09:14:42.314858 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:14:42.315223 [info ] [MainThread]: 
[0m09:14:42.315711 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:14:42.318739 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:14:42.347719 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:14:42.348270 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:14:42.348746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:14:42.361843 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m09:14:42.363049 [debug] [ThreadPool]: On list_analytics: Close
[0m09:14:42.364275 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:14:42.369067 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:14:42.369657 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:14:42.370140 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:14:42.379362 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m09:14:42.379971 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:14:42.380544 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:14:42.384754 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.004 seconds
[0m09:14:42.386049 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:14:42.386714 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:14:42.390696 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.391258 [debug] [MainThread]: On master: BEGIN
[0m09:14:42.391792 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:14:42.400225 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m09:14:42.400712 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.401213 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:14:42.407116 [debug] [MainThread]: SQL status: SELECT 1 in 0.005 seconds
[0m09:14:42.408517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb037fc70>]}
[0m09:14:42.409094 [debug] [MainThread]: On master: ROLLBACK
[0m09:14:42.409787 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.410245 [debug] [MainThread]: On master: BEGIN
[0m09:14:42.410930 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:14:42.411505 [debug] [MainThread]: On master: COMMIT
[0m09:14:42.412051 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.412526 [debug] [MainThread]: On master: COMMIT
[0m09:14:42.413061 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:14:42.413529 [debug] [MainThread]: On master: Close
[0m09:14:42.416647 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:14:42.417446 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:14:42.418040 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:14:42.418543 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:14:42.424388 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:14:42.425780 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:14:42.449968 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:14:42.451223 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.451729 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:14:42.452193 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:14:42.460105 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m09:14:42.460644 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.461064 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:14:42.464468 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m09:14:42.469067 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.469533 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:14:42.470161 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:14:42.472300 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.472723 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:14:42.473288 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:14:42.482804 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:14:42.483289 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.483706 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:14:42.485428 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:14:42.489355 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:14:42.492031 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:14:42.492440 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:14:42.493887 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:14:42.495522 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:14:42.496807 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf37a220>]}
[0m09:14:42.497401 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.08s]
[0m09:14:42.497895 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:14:42.498645 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:14:42.499073 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:14:42.499525 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:14:42.499931 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:14:42.517533 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.518015 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.518417 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:14:42.527876 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.009 seconds
[0m09:14:42.529081 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.529550 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.530405 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.531509 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.531948 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.532792 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.537153 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.537709 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.538476 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.539775 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.540316 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.541001 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.542168 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.542620 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.543175 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.544749 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.545292 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.545968 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.546971 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.547368 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.548068 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.549058 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.549457 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.550061 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.551552 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.551958 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.552576 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.553621 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.554031 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.554650 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.555649 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.556042 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:14:42.556637 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.563272 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.563708 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:14:42.564326 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.565528 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.565921 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:14:42.566559 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.567746 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.568157 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:14:42.568744 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.569894 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.570293 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:14:42.570857 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:14:42.589735 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.590201 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:14:42.590771 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:14:42.591169 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.591569 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:14:42.592447 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.000 seconds
[0m09:14:42.595330 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:14:42.597249 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:14:42.610831 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:14:42.612053 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.612820 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:14:42.629178 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.016 seconds
[0m09:14:42.634090 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.634580 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:14:42.635217 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:14:42.637400 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.637841 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:14:42.638391 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:14:42.639552 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:14:42.640026 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.640401 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:14:42.641783 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:14:42.643675 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:14:42.645375 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:14:42.645782 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:14:42.650953 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.005 seconds
[0m09:14:42.652033 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:14:42.652653 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48829bc6-87e3-4786-b83e-5697173d942b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac199970>]}
[0m09:14:42.653238 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.15s]
[0m09:14:42.653730 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:14:42.654916 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.655389 [debug] [MainThread]: On master: BEGIN
[0m09:14:42.655806 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:14:42.663118 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:14:42.663568 [debug] [MainThread]: On master: COMMIT
[0m09:14:42.663931 [debug] [MainThread]: Using postgres connection "master"
[0m09:14:42.664277 [debug] [MainThread]: On master: COMMIT
[0m09:14:42.664777 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:14:42.665144 [debug] [MainThread]: On master: Close
[0m09:14:42.665609 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:14:42.665982 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:14:42.666342 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:14:42.666749 [info ] [MainThread]: 
[0m09:14:42.667152 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.35 seconds (0.35s).
[0m09:14:42.667981 [debug] [MainThread]: Command end result
[0m09:14:42.700911 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:14:42.702471 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:14:42.707118 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:14:42.707503 [info ] [MainThread]: 
[0m09:14:42.707931 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:14:42.708280 [info ] [MainThread]: 
[0m09:14:42.708668 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:14:42.709435 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.90505964, "process_in_blocks": "0", "process_kernel_time": 0.24117, "process_mem_max_rss": "107768", "process_out_blocks": "0", "process_user_time": 1.609156}
[0m09:14:42.709958 [debug] [MainThread]: Command `dbt run` succeeded at 09:14:42.709893 after 0.91 seconds
[0m09:14:42.710358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1cd0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2f09550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffafe6cb20>]}
[0m09:14:42.710776 [debug] [MainThread]: Flushing usage events
[0m09:14:43.421189 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:21:28.353322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94598a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff936b4550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff936b44f0>]}


============================== 09:21:28.359984 | 600141a1-697d-43b5-8951-8508478d0363 ==============================
[0m09:21:28.359984 [info ] [MainThread]: Running with dbt=1.9.4
[0m09:21:28.360582 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/dbt/homework/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt --profile my_dbt_project run --project-dir=/opt/airflow/dags/dbt/homework --models models/mart models/staging --vars {"is_test": false, "data_date": "2025-05-12"}', 'send_anonymous_usage_stats': 'True'}
[0m09:21:28.523429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9375bf10>]}
[0m09:21:28.558917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94343f70>]}
[0m09:21:28.559910 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m09:21:28.623715 [debug] [MainThread]: checksum: a9eee3bc05c3a47247d4a92fdfa49a6142245abc9d8e5122bef96a906101da89, vars: {'data_date': '2025-05-12', 'is_test': False}, profile: my_dbt_project, target: , version: 1.9.4
[0m09:21:28.743172 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:21:28.743729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:21:28.747926 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- seeds.homework.iris_dataset
[0m09:21:28.768653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92778130>]}
[0m09:21:28.862572 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:21:28.867296 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:21:28.878415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff926eedf0>]}
[0m09:21:28.878962 [info ] [MainThread]: Found 2 models, 1 source, 587 macros
[0m09:21:28.879381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff928b1430>]}
[0m09:21:28.880617 [info ] [MainThread]: 
[0m09:21:28.881019 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:21:28.881380 [info ] [MainThread]: 
[0m09:21:28.881900 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:21:28.884644 [debug] [ThreadPool]: Acquiring new postgres connection 'list_analytics'
[0m09:21:28.912529 [debug] [ThreadPool]: Using postgres connection "list_analytics"
[0m09:21:28.913258 [debug] [ThreadPool]: On list_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics"} */

    select distinct nspname from pg_namespace
  
[0m09:21:28.913705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:21:28.925084 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m09:21:28.926162 [debug] [ThreadPool]: On list_analytics: Close
[0m09:21:28.927254 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_analytics, now list_analytics_analytics)
[0m09:21:28.931612 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:21:28.932067 [debug] [ThreadPool]: On list_analytics_analytics: BEGIN
[0m09:21:28.932449 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:21:28.939983 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m09:21:28.940365 [debug] [ThreadPool]: Using postgres connection "list_analytics_analytics"
[0m09:21:28.940678 [debug] [ThreadPool]: On list_analytics_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "list_analytics_analytics"} */
select
      'analytics' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics'
    union all
    select
      'analytics' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics'
  
[0m09:21:28.944518 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.004 seconds
[0m09:21:28.945466 [debug] [ThreadPool]: On list_analytics_analytics: ROLLBACK
[0m09:21:28.945961 [debug] [ThreadPool]: On list_analytics_analytics: Close
[0m09:21:28.949647 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:28.950188 [debug] [MainThread]: On master: BEGIN
[0m09:21:28.950589 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:21:28.957671 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m09:21:28.958101 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:28.958516 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:21:28.964186 [debug] [MainThread]: SQL status: SELECT 1 in 0.005 seconds
[0m09:21:28.965326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff929a7e80>]}
[0m09:21:28.965802 [debug] [MainThread]: On master: ROLLBACK
[0m09:21:28.966309 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:28.966701 [debug] [MainThread]: On master: BEGIN
[0m09:21:28.967266 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m09:21:28.967671 [debug] [MainThread]: On master: COMMIT
[0m09:21:28.968054 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:28.968416 [debug] [MainThread]: On master: COMMIT
[0m09:21:28.968893 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:21:28.969269 [debug] [MainThread]: On master: Close
[0m09:21:28.972145 [debug] [Thread-1  ]: Began running node model.homework.stg_iris
[0m09:21:28.972823 [info ] [Thread-1  ]: 1 of 2 START sql view model analytics.stg_iris ................................. [RUN]
[0m09:21:28.973344 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_analytics_analytics, now model.homework.stg_iris)
[0m09:21:28.973756 [debug] [Thread-1  ]: Began compiling node model.homework.stg_iris
[0m09:21:28.979145 [debug] [Thread-1  ]: Writing injected SQL for node "model.homework.stg_iris"
[0m09:21:28.980878 [debug] [Thread-1  ]: Began executing node model.homework.stg_iris
[0m09:21:29.003145 [debug] [Thread-1  ]: Writing runtime sql for node "model.homework.stg_iris"
[0m09:21:29.004801 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.005354 [debug] [Thread-1  ]: On model.homework.stg_iris: BEGIN
[0m09:21:29.005885 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:21:29.017972 [debug] [Thread-1  ]: SQL status: BEGIN in 0.012 seconds
[0m09:21:29.018654 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.019214 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */

  create view "analytics"."analytics"."stg_iris__dbt_tmp"
    
    
  as (
    with source as (
    select * from "analytics"."analytics"."iris_dataset"
)

select
    cast(sepal_length as numeric) sepal_length,
    cast(sepal_width as numeric) sepal_width,
    cast(petal_length as numeric) petal_length,
    cast(petal_width as numeric) petal_width,
    species
from source
  );
[0m09:21:29.027331 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.008 seconds
[0m09:21:29.039832 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.042077 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris" rename to "stg_iris__dbt_backup"
[0m09:21:29.043044 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:21:29.046063 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.047326 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
alter table "analytics"."analytics"."stg_iris__dbt_tmp" rename to "stg_iris"
[0m09:21:29.048763 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:21:29.059119 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:21:29.059870 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.060441 [debug] [Thread-1  ]: On model.homework.stg_iris: COMMIT
[0m09:21:29.062212 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m09:21:29.067204 [debug] [Thread-1  ]: Applying DROP to: "analytics"."analytics"."stg_iris__dbt_backup"
[0m09:21:29.071524 [debug] [Thread-1  ]: Using postgres connection "model.homework.stg_iris"
[0m09:21:29.072531 [debug] [Thread-1  ]: On model.homework.stg_iris: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.stg_iris"} */
drop view if exists "analytics"."analytics"."stg_iris__dbt_backup" cascade
[0m09:21:29.074265 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m09:21:29.076184 [debug] [Thread-1  ]: On model.homework.stg_iris: Close
[0m09:21:29.077425 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91c3d220>]}
[0m09:21:29.078034 [info ] [Thread-1  ]: 1 of 2 OK created sql view model analytics.stg_iris ............................ [[32mCREATE VIEW[0m in 0.10s]
[0m09:21:29.078605 [debug] [Thread-1  ]: Finished running node model.homework.stg_iris
[0m09:21:29.079371 [debug] [Thread-3  ]: Began running node model.homework.iris_processed
[0m09:21:29.079912 [info ] [Thread-3  ]: 2 of 2 START sql table model analytics.iris_processed .......................... [RUN]
[0m09:21:29.080430 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.homework.iris_processed'
[0m09:21:29.080843 [debug] [Thread-3  ]: Began compiling node model.homework.iris_processed
[0m09:21:29.099291 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.099908 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.100317 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m09:21:29.110408 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.010 seconds
[0m09:21:29.111669 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.112032 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.112781 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.113717 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.114056 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.114657 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.118874 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.119249 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.119816 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.120762 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.121097 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.121645 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.122609 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.122946 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.123520 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.124961 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.125371 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.125961 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.126937 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.127337 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.128005 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.128975 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.129363 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.129949 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.131339 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.131747 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.132328 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.133292 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.133681 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 - 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.134332 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.135297 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.135694 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

        select percentile_cont(0.5 + 0.5/2) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
    
[0m09:21:29.136270 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.143271 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.143853 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:21:29.144495 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.145856 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.146260 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by sepal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:21:29.146865 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.148081 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.148471 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_length ) from "analytics"."analytics"."stg_iris"
        
[0m09:21:29.149071 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.150244 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.150653 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

            select percentile_cont(0.5) within group (order by petal_width ) from "analytics"."analytics"."stg_iris"
        
[0m09:21:29.151226 [debug] [Thread-3  ]: SQL status: SELECT 1 in 0.000 seconds
[0m09:21:29.170475 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.170972 [debug] [Thread-3  ]: On model.homework.iris_processed: BEGIN
[0m09:21:29.171532 [debug] [Thread-3  ]: SQL status: BEGIN in 0.000 seconds
[0m09:21:29.171894 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.172206 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
select
                species as value

            from "analytics"."analytics"."stg_iris"

            
            where species is not null  and true
            

            group by species
            order by species

            

        
[0m09:21:29.173013 [debug] [Thread-3  ]: SQL status: SELECT 3 in 0.000 seconds
[0m09:21:29.175902 [debug] [Thread-3  ]: Writing injected SQL for node "model.homework.iris_processed"
[0m09:21:29.176909 [debug] [Thread-3  ]: Began executing node model.homework.iris_processed
[0m09:21:29.191118 [debug] [Thread-3  ]: Writing runtime sql for node "model.homework.iris_processed"
[0m09:21:29.192637 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.193384 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */

  
    

  create  table "analytics"."analytics"."iris_processed__dbt_tmp"
  
  
    as
  
  (
    

with import_iris as (
    select *
    from "analytics"."analytics"."stg_iris"
)
select
    sepal_length,
    sepal_width,
    petal_length,
    petal_width,
    -- K Bins Discretization
    
        

    
        NTILE(5) over (order by sepal_length)
    

 as sepal_length_quantile_bin,
        

    
        
        floor(
        (
            sepal_length - (min(sepal_length) over ())
        )
        /
        (
            ((max(sepal_length) over ()) - (min(sepal_length) over ())) / 4::float
        )
        ) + 1
    

 as sepal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by sepal_width)
    

 as sepal_width_quantile_bin,
        

    
        
        floor(
        (
            sepal_width - (min(sepal_width) over ())
        )
        /
        (
            ((max(sepal_width) over ()) - (min(sepal_width) over ())) / 4::float
        )
        ) + 1
    

 as sepal_width_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_length)
    

 as petal_length_quantile_bin,
        

    
        
        floor(
        (
            petal_length - (min(petal_length) over ())
        )
        /
        (
            ((max(petal_length) over ()) - (min(petal_length) over ())) / 4::float
        )
        ) + 1
    

 as petal_length_uniform_bin,
    
        

    
        NTILE(5) over (order by petal_width)
    

 as petal_width_quantile_bin,
        

    
        
        floor(
        (
            petal_width - (min(petal_width) over ())
        )
        /
        (
            ((max(petal_width) over ()) - (min(petal_width) over ())) / 4::float
        )
        ) + 1
    

 as petal_width_uniform_bin,
    
-- Scaling
    
        

    

    
    
    

    
    
    

    (
        sepal_length - 5.8
    )
    /
    (
        6.4 - 5.1
    )

 as sepal_length_robust_scaled,
        

    (sepal_length) / (max(abs(sepal_length)) over ())::FLOAT

 as sepal_length_max_absolute_scaled,
        

    
    (
        ((sepal_length) - (min(sepal_length) over ()))
        /
        ((max(sepal_length) over ()) - (min(sepal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        sepal_width - 3.0
    )
    /
    (
        3.3 - 2.8
    )

 as sepal_width_robust_scaled,
        

    (sepal_width) / (max(abs(sepal_width)) over ())::FLOAT

 as sepal_width_max_absolute_scaled,
        

    
    (
        ((sepal_width) - (min(sepal_width) over ()))
        /
        ((max(sepal_width) over ()) - (min(sepal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as sepal_width_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_length - 4.35
    )
    /
    (
        5.1 - 1.6
    )

 as petal_length_robust_scaled,
        

    (petal_length) / (max(abs(petal_length)) over ())::FLOAT

 as petal_length_max_absolute_scaled,
        

    
    (
        ((petal_length) - (min(petal_length) over ()))
        /
        ((max(petal_length) over ()) - (min(petal_length) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_length_max_min_max_scaled,
    
        

    

    
    
    

    
    
    

    (
        petal_width - 1.3
    )
    /
    (
        1.8 - 0.3
    )

 as petal_width_robust_scaled,
        

    (petal_width) / (max(abs(petal_width)) over ())::FLOAT

 as petal_width_max_absolute_scaled,
        

    
    (
        ((petal_width) - (min(petal_width) over ()))
        /
        ((max(petal_width) over ()) - (min(petal_width) over ()))::FLOAT
    )
    *
    (1.0 - 0.0)
    +
    0.0

 as petal_width_max_min_max_scaled,
    

    -- Log Transformation
    
        

    case
        when sepal_length is null or sepal_length + 0 <= 0 then null
        else log(10, sepal_length + 0)
    end

 as sepal_length_logged,
    
        

    case
        when sepal_width is null or sepal_width + 0 <= 0 then null
        else log(10, sepal_width + 0)
    end

 as sepal_width_logged,
    
        

    case
        when petal_length is null or petal_length + 0 <= 0 then null
        else log(10, petal_length + 0)
    end

 as petal_length_logged,
    
        

    case
        when petal_width is null or petal_width + 0 <= 0 then null
        else log(10, petal_width + 0)
    end

 as petal_width_logged,
    

    -- Binarization
    
        

    

    
        

        
    

    case
        when sepal_length >=
            
                5.8
            
            then 1
        else 0
    end

 as sepal_length_binarized,
    
        

    

    
        

        
    

    case
        when sepal_width >=
            
                3.0
            
            then 1
        else 0
    end

 as sepal_width_binarized,
    
        

    

    
        

        
    

    case
        when petal_length >=
            
                4.35
            
            then 1
        else 0
    end

 as petal_length_binarized,
    
        

    

    
        

        
    

    case
        when petal_width >=
            
                1.3
            
            then 1
        else 0
    end

 as petal_width_binarized,
    

    -- Standardization
    
        

    
    (
        (sepal_length - avg(sepal_length) over ())
        /
        (stddev(sepal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_length_standardized,
    
        

    
    (
        (sepal_width - avg(sepal_width) over ())
        /
        (stddev(sepal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as sepal_width_standardized,
    
        

    
    (
        (petal_length - avg(petal_length) over ())
        /
        (stddev(petal_length) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_length_standardized,
    
        

    
    (
        (petal_width - avg(petal_width) over ())
        /
        (stddev(petal_width) over ())::FLOAT
    )
    *
    1
    +
    0

 as petal_width_standardized,
    
-- Interactions
    
        
            
            
            

    
        (sepal_length * sepal_width)
    

 as sepal_length_x_sepal_width_interaction,
            

    
        (sepal_length + sepal_width)
    

 as sepal_length_plus_sepal_width_interaction,
        
            
            
            

    
        (sepal_length * petal_length)
    

 as sepal_length_x_petal_length_interaction,
            

    
        (sepal_length + petal_length)
    

 as sepal_length_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_length * petal_width)
    

 as sepal_length_x_petal_width_interaction,
            

    
        (sepal_length + petal_width)
    

 as sepal_length_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (sepal_width * petal_length)
    

 as sepal_width_x_petal_length_interaction,
            

    
        (sepal_width + petal_length)
    

 as sepal_width_plus_petal_length_interaction,
        
            
            
            

    
        (sepal_width * petal_width)
    

 as sepal_width_x_petal_width_interaction,
            

    
        (sepal_width + petal_width)
    

 as sepal_width_plus_petal_width_interaction,
        
    
        
            
            
            

    
        (petal_length * petal_width)
    

 as petal_length_x_petal_width_interaction,
            

    
        (petal_length + petal_width)
    

 as petal_length_plus_petal_width_interaction,
        
    
        
    
species,    
    -- Label Encoding
    

    dense_rank() over (order by species) - 1

 as species_label_encoded,
    -- One Hot Encoding
    

    

    
        
    

    

    

        case
            when species = 'setosa' then 1
            else 0
        end as is_species__setosa,

    

        case
            when species = 'versicolor' then 1
            else 0
        end as is_species__versicolor,

    

        case
            when species = 'virginica' then 1
            else 0
        end as is_species__virginica,

    

    case
        when species is null then 1
        else 0
    end as is_species__


from "analytics"."analytics"."stg_iris"
  );
  
[0m09:21:29.210867 [debug] [Thread-3  ]: SQL status: SELECT 150 in 0.017 seconds
[0m09:21:29.216420 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.216991 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed" rename to "iris_processed__dbt_backup"
[0m09:21:29.217826 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:21:29.220227 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.220639 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
alter table "analytics"."analytics"."iris_processed__dbt_tmp" rename to "iris_processed"
[0m09:21:29.221255 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m09:21:29.222591 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:21:29.223051 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.223425 [debug] [Thread-3  ]: On model.homework.iris_processed: COMMIT
[0m09:21:29.224633 [debug] [Thread-3  ]: SQL status: COMMIT in 0.001 seconds
[0m09:21:29.226720 [debug] [Thread-3  ]: Applying DROP to: "analytics"."analytics"."iris_processed__dbt_backup"
[0m09:21:29.228615 [debug] [Thread-3  ]: Using postgres connection "model.homework.iris_processed"
[0m09:21:29.229033 [debug] [Thread-3  ]: On model.homework.iris_processed: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "my_dbt_project", "target_name": "dev", "node_id": "model.homework.iris_processed"} */
drop table if exists "analytics"."analytics"."iris_processed__dbt_backup" cascade
[0m09:21:29.234469 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.005 seconds
[0m09:21:29.235675 [debug] [Thread-3  ]: On model.homework.iris_processed: Close
[0m09:21:29.236484 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600141a1-697d-43b5-8951-8508478d0363', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90269a00>]}
[0m09:21:29.237317 [info ] [Thread-3  ]: 2 of 2 OK created sql table model analytics.iris_processed ..................... [[32mSELECT 150[0m in 0.16s]
[0m09:21:29.238024 [debug] [Thread-3  ]: Finished running node model.homework.iris_processed
[0m09:21:29.239466 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:29.239954 [debug] [MainThread]: On master: BEGIN
[0m09:21:29.240381 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:21:29.248373 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m09:21:29.249075 [debug] [MainThread]: On master: COMMIT
[0m09:21:29.249566 [debug] [MainThread]: Using postgres connection "master"
[0m09:21:29.250013 [debug] [MainThread]: On master: COMMIT
[0m09:21:29.250532 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m09:21:29.251037 [debug] [MainThread]: On master: Close
[0m09:21:29.251540 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:21:29.252056 [debug] [MainThread]: Connection 'model.homework.stg_iris' was properly closed.
[0m09:21:29.252598 [debug] [MainThread]: Connection 'model.homework.iris_processed' was properly closed.
[0m09:21:29.253154 [info ] [MainThread]: 
[0m09:21:29.253677 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m09:21:29.254534 [debug] [MainThread]: Command end result
[0m09:21:29.287847 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/dbt/homework/target/manifest.json
[0m09:21:29.289709 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/dbt/homework/target/semantic_manifest.json
[0m09:21:29.294587 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/dbt/homework/target/run_results.json
[0m09:21:29.295013 [info ] [MainThread]: 
[0m09:21:29.295444 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:21:29.295814 [info ] [MainThread]: 
[0m09:21:29.296191 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:21:29.297003 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0007511, "process_in_blocks": "0", "process_kernel_time": 0.232185, "process_mem_max_rss": "107708", "process_out_blocks": "0", "process_user_time": 1.726692}
[0m09:21:29.297499 [debug] [MainThread]: Command `dbt run` succeeded at 09:21:29.297441 after 1.00 seconds
[0m09:21:29.297915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94598a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92717730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92717fd0>]}
[0m09:21:29.298324 [debug] [MainThread]: Flushing usage events
[0m09:21:29.997308 [debug] [MainThread]: An error was encountered while trying to flush usage events
